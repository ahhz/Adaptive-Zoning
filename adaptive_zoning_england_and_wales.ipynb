{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4399b8-21da-439b-afa4-afefd6aad207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not have these datafiles yet, use the adaptive_zoning_preprocess_EW_data\n",
    "# notebook to download and preprocess the data.\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "centroid_data = gpd.read_parquet('data/centroid_data.parquet')\n",
    "commuting_data = pd.read_parquet('data/commuting_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a212178-7609-4b28-973a-ed96a0f18c55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note: on my laptop this takes up to 4 minutes\n",
    "# See the next cells to dump / load a pickle of the adaptive_zone_system\n",
    "from time import time\n",
    "from adaptive_zoning import AdaptiveZoneSystem\n",
    "\n",
    "t = time()\n",
    "\n",
    "centroids = [(pt.x,pt.y) for pt in centroid_data.geometry]\n",
    "pop =  centroid_data['Residential population'].to_list()\n",
    "emp =  centroid_data['Workplace population'].to_list() \n",
    "\n",
    "# Using population as weights. This is a deviation from the paper which used area-weighted centroids\n",
    "weight = pop\n",
    "\n",
    "# For the estimation of beta, see separate notebook on doubly-constrained model estimation.\n",
    "beta = 0.11253833770751953 / 1000 # taken from doubly constrained calibration\n",
    "\n",
    "nbh_size = 72 # reduce to 1% of original OD pairs\n",
    "\n",
    "zone_system = AdaptiveZoneSystem(pop, emp, weight, centroids, beta, nbh_size)\n",
    "\n",
    "print(\"Calculation took: \", time()-t, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafe3e2-4a8b-4d1c-9d11-ce33c0e7c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Pickle the adaptive zone sytem for England and Wales\n",
    "filename = \"data/zone_system_EW.pkl\"\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(zone_system, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8197b-acff-44c7-8ff3-b6b27f9e21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Unpickling the adaptive zone system for England and Wales\n",
    "filename = \"data/zone_system_EW.pkl\"\n",
    "with open(filename, 'rb') as file:\n",
    "    zone_system = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b87e1-5e2d-403f-ab8e-3bd22bb5a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 9))\n",
    "zone_system.plot_n_clusters_voronoi(1018, ax[0])\n",
    "zone_system.plot_neighbourhood_voronoi(800, ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68461053-9783-4a49-bb28-7d67aaa2ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_helper import get_key\n",
    "openroute_api_key = get_key(\"OpenRouteService\",\"API key\",\"config.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18fe6e7-0ffc-4207-bd1e-224728edc2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize results separately, so the next cell can be run multiple times to collect more data.\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce935ed-e3d1-4a5f-a73c-8ce2bb0f8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import random\n",
    "\n",
    "from openroute_distance import bng_to_wgs84\n",
    "from openroute_distance import get_full_distance\n",
    "from openroute_distance import get_halfway_distance\n",
    "\n",
    "def straightline_distance(a,b):\n",
    "    dx = a[0] - b[0]\n",
    "    dy = a[1] - b[1]\n",
    "    return sqrt(dx**2 + dy**2)\n",
    " \n",
    "cluster = zone_system.map_leaf_zones_to_n_clusters(1018, False)\n",
    "centroids = zone_system.get_centroids()\n",
    "\n",
    "centroids_wgs84 = bng_to_wgs84(centroids)\n",
    "\n",
    "#  sample commuters, this will give good distribution of msoa, representative of commuting patterns\n",
    "sample_size = 10\n",
    "zones = list(zip(commuting_data['Area of residence'], commuting_data['Area of workplace']))\n",
    "weights = list(commuting_data['Commuters'])\n",
    "codes = random.choices(zones, weights, k = sample_size)\n",
    "get_index = lambda zone: centroid_data.loc[centroid_data['msoa11cd'] == zone].index[0]\n",
    "sample = [(get_index(a),get_index(b)) for a,b in codes]\n",
    "for a,b in sample:\n",
    "    a_trad = cluster[a]\n",
    "    b_trad = cluster[b]\n",
    "\n",
    "    a_adapt = zone_system.find_aggregated_neighbour(b, a)\n",
    "    b_adapt = zone_system.find_aggregated_neighbour(a, b)\n",
    "    \n",
    "    centroids_wgs84_a = centroids_wgs84[a]\n",
    "    centroids_wgs84_b = centroids_wgs84[b]\n",
    "    \n",
    "    centroids_wgs84_a_trad = centroids_wgs84[a_trad]\n",
    "    centroids_wgs84_b_trad = centroids_wgs84[b_trad]\n",
    "    \n",
    "    centroids_wgs84_a_adapt = centroids_wgs84[a_adapt]\n",
    "    centroids_wgs84_b_adapt = centroids_wgs84[b_adapt]\n",
    "\n",
    "    centroids_bgn_a = centroids[a]\n",
    "    centroids_bgn_b = centroids[b]\n",
    "\n",
    "    centroids_bgn_a_trad = centroids[a_trad]\n",
    "    centroids_bgn_b_trad = centroids[b_trad]\n",
    "    \n",
    "    centroids_bgn_a_adapt = centroids[a_adapt]\n",
    "    centroids_bgn_b_adapt = centroids[b_adapt]\n",
    "\n",
    "    straight_full    = straightline_distance(centroids_bgn_a       ,centroids_bgn_b)\n",
    "    straight_trad    = straightline_distance(centroids_bgn_a_trad  ,centroids_bgn_b_trad)\n",
    "    straight_adapt_1 = straightline_distance(centroids_bgn_a       ,centroids_bgn_b_adapt)\n",
    "    straight_adapt_2 = straightline_distance(centroids_bgn_a_adapt ,centroids_bgn_b)\n",
    "\n",
    "    network_full     = get_full_distance(   centroids_wgs84_a       , centroids_wgs84_b        ,\"driving-car\", openroute_api_key)['duration']\n",
    "    network_trad     = get_full_distance(   centroids_wgs84_a_trad  , centroids_wgs84_b_trad   ,\"driving-car\", openroute_api_key)['duration']\n",
    "    network_adapt_1  = get_halfway_distance(centroids_wgs84_a       , centroids_wgs84_b_adapt ,\"driving-car\",openroute_api_key,True)['duration']\n",
    "    network_adapt_2  = get_halfway_distance(centroids_wgs84_a_adapt , centroids_wgs84_b       ,\"driving-car\",openroute_api_key,False)['duration']\n",
    "   \n",
    "    if all([v != None for v in [network_full, network_trad, network_adapt_1, network_adapt_2]]):\n",
    "        \n",
    "        straight_adapt = (straight_adapt_1 + straight_adapt_2)/2\n",
    "        network_adapt = network_adapt_1 + network_adapt_2\n",
    "\n",
    "        # avoid division by zero\n",
    "        if straight_trad == 0 : straight_trad  = 1\n",
    "        if straight_adapt == 0: straight_adapt = 1\n",
    "        \n",
    "        network_trad_best_guess  = straight_full * network_trad / straight_trad\n",
    "        network_adapt_best_guess = straight_full * network_adapt/ straight_adapt\n",
    "        \n",
    "        results.append((network_full, network_trad_best_guess, network_adapt_best_guess))\n",
    "\n",
    "print(len(results))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65988d08-9b63-4169-a2e4-3a97648ae32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def plot_aggregation_comparison(data):\n",
    "    \"\"\"\n",
    "    Plots a scatter plot comparing traditional and adaptive aggregation against accurate values,\n",
    "    when the data is in a list of tuples.\n",
    "\n",
    "    Args:\n",
    "        data: List of tuples, where each tuple contains (accurate_value, traditional_value, adaptive_value).\n",
    "    \"\"\"\n",
    "\n",
    "    accurate_values = [item[0] for item in data]\n",
    "    traditional_values = [item[1] for item in data]\n",
    "    adaptive_values = [item[2] for item in data]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Scatter plot for traditional aggregation\n",
    "    plt.scatter(accurate_values, traditional_values, label='Traditional Aggregation', marker='o')\n",
    "\n",
    "    # Scatter plot for adaptive aggregation\n",
    "    plt.scatter(accurate_values, adaptive_values, label='Adaptive Aggregation', marker='x')\n",
    "\n",
    "    # Calculate R-squared for traditional aggregation\n",
    "    r2_traditional = r2_score(accurate_values, traditional_values)\n",
    "    plt.text(0.05, 0.95, f'R² (Traditional): {r2_traditional:.3f}', transform=plt.gca().transAxes, verticalalignment='top')\n",
    "\n",
    "    # Calculate R-squared for adaptive aggregation\n",
    "    r2_adaptive = r2_score(accurate_values, adaptive_values)\n",
    "    plt.text(0.05, 0.90, f'R² (Adaptive): {r2_adaptive:.3f}', transform=plt.gca().transAxes, verticalalignment='top')\n",
    "    improvement_factor = (1-r2_traditional)/(1-r2_adaptive)\n",
    "    plt.text(0.05, 0.85, f'Improvement factor: {improvement_factor:.3f}', transform=plt.gca().transAxes, verticalalignment='top')\n",
    "  \n",
    "    # Add the y=x line (accurate prediction line)\n",
    "    min_val = min(min(accurate_values), min(traditional_values), min(adaptive_values))\n",
    "    max_val = max(max(accurate_values), max(traditional_values), max(adaptive_values))\n",
    "\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='y=x (Accurate)')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Accurate Values')\n",
    "    plt.ylabel('Aggregated Values')\n",
    "    plt.title('Aggregation Comparison - Travel time (s)')\n",
    "    #plt.xlim(0,5400)\n",
    "    #plt.ylim(0,5400)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "plot_aggregation_comparison(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba6361-e978-417f-a312-dd7f5f78afde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
